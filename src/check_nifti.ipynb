{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glm_func \n",
    "from nilearn.image import mean_img\n",
    "from nilearn import plotting\n",
    "import glob as glob\n",
    "from nilearn.plotting import plot_img, plot_epi, plot_roi, plot_stat_map\n",
    "from nilearn import image\n",
    "import importlib\n",
    "import nibabel as nib   \n",
    "import numpy as np\n",
    "#importlib.reload(func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn\n",
    "\n",
    "print(\"Nilearn version:\", nilearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = r'/home/dsutterlin/projects/resting_state_hypnosis/resting_state_hypnosis/debug/'\n",
    "os.chdir(pwd)\n",
    "func_asl_path = r'/home/dsutterlin/projects/test_data/ASL_RS_hypnosis/CBF_4D_normalized/'\n",
    "img = nib.load('all_cond_mean_img.nii.gz')\n",
    "print(img.shape)\n",
    "ts = nib.load('/home/dsutterlin/projects/test_data/ASL_RS_hypnosis/CBF_4D_normalized/APM_15_H2/wcbf_0_srASL_4D_during_4D.nii')\n",
    "print(ts.shape)\n",
    "!ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voxel masker (whole brain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desmarteaux data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import nibabel as nib\n",
    "func_path = '/home/dsutterlin/projects/test_data/desmarteauxSugg/APM_26_H1'\n",
    "file_list = glob.glob(os.path.join(func_path, 'swaf*.nii'))\n",
    "file_list.sort()\n",
    "\n",
    "func = nib.concat_images(file_list)\n",
    "print(func.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image\n",
    "#func = nib.load(func_path)\n",
    "mean_img = image.mean_img(func)\n",
    "print(mean_img.shape)\n",
    "plotting.view_img(mean_img, bg_img='MNI152', title='mean img with MNI BG').save_as_html('mean_img.html')\n",
    "plotting.plot_img(mean_img, title = 'mean_img',)\n",
    "\n",
    "voxel_masker = NiftiMasker(\n",
    "    mask_strategy = 'whole-brain-template',\n",
    "    smoothing_fwhm = 6,\n",
    "    verbose=5,\n",
    ")\n",
    "voxel_masker.fit(func_asl)\n",
    "voxel_masker.generate_report().save_as_html('masker_report.html')\n",
    "plotting.plot_roi(voxel_masker.mask_img_, title='Mask')\n",
    "plotting.plot_img(image.math_img(\"img1 * img2\", img1=mean_img, img2=voxel_masker.mask_img_), title='Mean Image with Voxel Mask')\n",
    "plotting.view_img(image.math_img(\"img1 * img2\", img1=mean_img, img2=voxel_masker.mask_img_), title='Mean Image with Voxel Mask').save_as_html('view_image_plot.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASL data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image\n",
    "from nilearn.maskers import NiftiMasker\n",
    "func_asl = nib.load(os.path.join(func_asl_path,'APM_15_H2/wcbf_0_srASL_4D_during_4D.nii'))\n",
    "mean_img_asl = image.mean_img(func_asl)\n",
    "print(mean_img_asl.shape)\n",
    "plotting.view_img(mean_img_asl, bg_img='MNI152', title='mean img with MNI BG').save_as_html('mean_img.html')\n",
    "plotting.plot_img(mean_img_asl, title = 'mean_img',)\n",
    "\n",
    "voxel_masker = NiftiMasker(\n",
    "    mask_strategy = 'whole-brain-template',\n",
    "    smoothing_fwhm = 6,\n",
    "    verbose=5,\n",
    ")\n",
    "voxel_masker.fit(func_asl) \n",
    "ts = voxel_masker.transform(func_asl)\n",
    "masked_img = voxel_masker.inverse_transform(ts) \n",
    "voxel_masker.generate_report().save_as_html('masker_asl_report.html')\n",
    "plotting.plot_roi(voxel_masker.mask_img_, title='Mask')\n",
    "plotting.plot_img(image.math_img(\"img1 * img2\", img1=mean_img_asl, img2=voxel_masker.mask_img_), title='Mean Image with Voxel Mask')\n",
    "plotting.view_img(image.math_img(\"img1 * img2\", img1=mean_img_asl, img2=voxel_masker.mask_img_), title='Mean Image with Voxel Mask').save_as_html('view_asl_plot.html')\n",
    "plotting.plot_img(mean_img(masked_img), title = 'Masked Image')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MNI152 binary mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.datasets import load_mni152_template, load_mni152_gm_template\n",
    "from nilearn.image import math_img, resample_to_img\n",
    "from nilearn import image\n",
    "from nilearn.maskers import  NiftiMasker\n",
    "from nilearn.plotting import plot_roi, plot_img\n",
    "\n",
    "# Import MNI template\n",
    "mni_template = load_mni152_template()\n",
    "\n",
    "# Binarize MNI template\n",
    "bin_mni_mask = math_img(\"img > 0\", img=mni_template)\n",
    "print(mean_img.affine)\n",
    "# Resample bin_mni_mask to mean_img affine\n",
    "resampled_bin_mni_mask = resample_to_img(bin_mni_mask, mean_img)\n",
    "\n",
    "# Initialize NiftiMasker with mask_img as the resampled binarized mask\n",
    "masker = NiftiMasker(mask_img=resampled_bin_mni_mask, mask_strategy='whole-brain-template', smoothing_fwhm=6)\n",
    "masker.fit(func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nilearn import image\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "\n",
    "# Assuming func_asl is your 4D image\n",
    "print(func_asl.shape)\n",
    "\n",
    "# Convert 4D image to a NumPy array\n",
    "asl_data = func_asl.get_fdata()\n",
    "print(asl_data.shape)\n",
    "# Specify the indices of volumes to be removed (e.g., remove volume 9)\n",
    "new_labels = [lab for i, lab in enumerate(labels) if i not in [0,3,5]]\n",
    "print(labels, new_labels) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image\n",
    "from nilearn.input_data import NiftiMapsMasker\n",
    "from nilearn import plotting\n",
    "\n",
    "atlas_path = '/home/dsutterlin/projects/resting_state_hypnosis/resting_state_hypnosis/atlases/atlas_difumo64/64difumo2mm_maps.nii.gz'\n",
    "\n",
    "# Load the functional image\n",
    "func_asl = nib.load(os.path.join(func_asl_path, 'APM_15_H2/wcbf_0_srASL_4D_during_4D.nii'))\n",
    "\n",
    "print(mean_img_asl.shape)\n",
    "print(nib.load(atlas_path).shape)\n",
    "# View the mean image with MNI background\n",
    "plotting.view_img(mean_img_asl, bg_img='MNI152', title='mean img with MNI BG').save_as_html('mean_img.html')\n",
    "plotting.plot_img(mean_img_asl, title='mean_img')\n",
    "\n",
    "# Define the NiftiMapsMasker\n",
    "mapsmasker = NiftiMapsMasker(maps_img=atlas_path,mask_img=voxel_masker.mask_img_, smoothing_fwhm=6, verbose=5, resampling_target = 'data')\n",
    "\n",
    "# Fit the masker to the functional image\n",
    "mapsmasker.fit(func_asl)\n",
    "\n",
    "# Generate the masker report and save it as HTML\n",
    "mapsmasker.generate_report(displayed_maps=64).save_as_html('masked-masker_asl_report.html')\n",
    "\n",
    "# Plot the mask\n",
    "plotting.plot_roi(mapsmasker.mask_img_, title='Mask')\n",
    "\n",
    "# Compute the mean image with the voxel mask\n",
    "mean_img_masked = image.math_img(\"img1 * img2\", img1=mean_img_asl, img2=voxel_masker.mask_img_)\n",
    "\n",
    "# Plot the mean image with the voxel mask\n",
    "plotting.plot_img(mean_img_masked, title='Mean Image with maps Mask')\n",
    "\n",
    "# View the mean image with the voxel mask and save it as HTML\n",
    "plotting.view_img(mean_img_masked, title='Mean Image with maps Mask').save_as_html('masked-view_asl_plot.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #all_mean_img = image.mean_img(pre_data + post_data)\n",
    "        #voxel_masker.fit(image.concat_imgs(pre_data+post_data))\n",
    "        #niftimask = voxel_masker.mask_img_\n",
    "        #nib.save(niftimask, os.path.join(pwd_main, 'debug', 'BG-voxelmask.nii.gz'))\n",
    "        #plotting.plot_roi(niftimask, title='Whole brain voxel mask')\n",
    "        #plotting.plot_stat_map(voxel_masker.mask_img_)\n",
    "        #voxel_masker_report = voxel_masker.generate_report()\n",
    "        #voxel_masker_report.save_as_html(os.path.join(pwd_main, 'debug', 'reports', 'voxel_masker_report.html'))\n",
    "        \n",
    "        print('---MAKING MASKER REPORTS---')\n",
    "        print('---Voxel masker---')\n",
    "        print('---Atlas and maps masker---')\n",
    "        masker_report = masker.generate_report()\n",
    "        masker_report.save_as_html(os.path.join(pwd_main, 'debug','reports','masker_report.html'))\n",
    "        nib.save(atlas, os.path.join(pwd_main, 'debug', 'atlas.nii.gz'))\n",
    "        resamp_mask = image.resample_img(masker.mask_img_, all_mean_img) #(img to resamp, target)\n",
    "        nib.save(resamp_mask, os.path.join(pwd_main, 'debug', 'resampled_masker.nii.gz'))\n",
    "        nib.save(masker.mask_img_, os.path.join(pwd_main, 'debug', 'masker.nii.gz'))\n",
    "        nib.save(masker.mask_img_, os.path.join(pwd_main, 'debug','resampled_masker.nii.gz'))\n",
    "        nib.save(all_mean_img, os.path.join(pwd_main, 'debug','all_cond_mean_img.nii.gz'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treshold image based on values\n",
    "from nilearn.image import binarize_img\n",
    "clean_img = image.clean_img(ts, ensure_finite=True)\n",
    "print(clean_img.shape)\n",
    "fdata = ts.get_fdata()\n",
    "print(np.unique(fdata,return_counts=True))\n",
    "print(min(fdata.flatten()), max(fdata.flatten()))\n",
    "#plotting.view_img(image.mean_img(clean_img), colorbar=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sphere masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiSpheresMasker\n",
    "from nilearn.maskers import NiftiSpheresMasker\n",
    "\n",
    "from nilearn import plotting\n",
    "\n",
    "# Define the coordinates of the spheres\n",
    "sphere_coords = [\n",
    "    (54, -28, 26),\n",
    "    (-20, -26, -14),\n",
    "    (-2, 20, 32),\n",
    "    (-8, 44, 28),\n",
    "    (-6, -26, 46),\n",
    "]\n",
    "\n",
    "# Create the NiftiSphereMasker\n",
    "sphere_masker = NiftiSpheresMasker(sphere_coords,mask_img=voxel_masker.mask_img_,  radius=6).fit(func_asl)\n",
    "\n",
    "# Apply the masker to the functional images\n",
    "\n",
    "masked_data = sphere_masker.transform(func_asl)\n",
    "print(masked_data.shape)\n",
    "# Plot the masked data on a glass brain\n",
    "#plotting.plot_glass_brain(sphere_masker.inverse_transform(masked_data), title='Sphere Masker')\n",
    "\n",
    "#report = sphere_masker.generate_report()\n",
    "#r#eport\n",
    "# Generate the masker report and save it as HTML\n",
    "#report = sphere_masker.generate_report('all')\n",
    "#report.save_as_html('sphere-masker-report.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets, plotting\n",
    "dataset = datasets.fetch_development_fmri(n_subjects=1)\n",
    "\n",
    "# print basic information on the dataset\n",
    "print(f\"First subject functional nifti image (4D) is at: {dataset.func[0]}\")\n",
    "dmn_coords = [(0, -52, 18), (-46, -68, 32), (46, -68, 32), (1, 50, -5)]\n",
    "labels = [\n",
    "    \"Posterior Cingulate Cortex\",\n",
    "    \"Left Temporoparietal junction\",\n",
    "    \"Right Temporoparietal junction\",\n",
    "    \"Medial prefrontal cortex\",\n",
    "]\n",
    "from nilearn.maskers import NiftiSpheresMasker\n",
    "\n",
    "masker = NiftiSpheresMasker(\n",
    "    dmn_coords,\n",
    "    radius=8,\n",
    "    detrend=True,\n",
    "    standardize=\"zscore_sample\",\n",
    "    standardize_confounds=\"zscore_sample\",\n",
    "    low_pass=0.1,\n",
    "    high_pass=0.01,\n",
    "    t_r=2,\n",
    "    memory=\"nilearn_cache\",\n",
    "    memory_level=1,\n",
    "    verbose=2,\n",
    "    clean__butterworth__padtype=\"even\",  # kwarg to modify Butterworth filter\n",
    ")\n",
    "\n",
    "# Additionally, we pass confound information to ensure our extracted\n",
    "# signal is cleaned from confounds.\n",
    "\n",
    "func_filename = dataset.func[0]\n",
    "confounds_filename = dataset.confounds[0]\n",
    "\n",
    "time_series = masker.fit_transform(\n",
    "    func_filename, confounds=[confounds_filename]\n",
    ")\n",
    "report = masker.generate_report()\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import  mean_img\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.datasets import load_mni152_brain_mask\n",
    "from nilearn.image import binarize_img\n",
    "from nilearn.image import clean_img\n",
    "\n",
    "import numpy as np\n",
    "p_data = r'home/dsutterlin/projects/test_data/ASL_RS_hypnosis/CBF_4D_normalized/APM_15_H2'\n",
    "test_img = nib.load(os.path.join(test_data, 'APM_15_H2', 'wcbf_0_srASL_4D_during_4D.nii'))\n",
    "#mask_img= nib.load(os.path.join(test_data, 'APM_15_H2', 'meanCBF_0_srASL_4D_during.nii'))\n",
    "print(clean_img(nib.load('all_cond_mean_img.nii.gz')).shape)\n",
    "mask_img = load_mni152_brain_mask(resolution=2)\n",
    "print(mask_img.affine)\n",
    "print(mask_img.shape)\n",
    "resamp_mni = binarize_img(image.resample_to_img(mask_img, 'all_cond_mean_img.nii.gz'))\n",
    "print(resamp_mni.affine)\n",
    "print(resamp_mni.shape)\n",
    "print(np.unique(resamp_mni.get_fdata(), return_counts=True))\n",
    "#mean img\n",
    "print(np.unique(nib.load('all_cond_mean_img.nii.gz').get_fdata(), return_counts=True))\n",
    "\n",
    "voxel_masker = NiftiMasker(\n",
    "    mask_img= resamp_mni,\n",
    "    standardize=\"zscore_sample\",\n",
    "    mask_strategy = 'whole-brain-template',\n",
    "    verbose=5,\n",
    ")\n",
    "voxel_masker.fit('all_cond_mean_img.nii.gz',)\n",
    "report = voxel_masker.generate_report()\n",
    "\n",
    "#oxel_masker = nib.load('1-voxelmask.nii.gz')\n",
    "plotting.plot_roi('all_cond_mean_img.nii.gz',bg_img= resamp_mni, cmap='Paired')\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "p = r'/home/dsutterlin/projects/resting_state_hypnosis/resting_state_hypnosis/debug/fitted_timeSeries.pkl'\n",
    "lab = r'/home/dsutterlin/projects/resting_state_hypnosis/resting_state_hypnosis/debug/labels.pkl'\n",
    "with open(p,  'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "with open(lab, 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data['pre_series'][0][43], label=labels[43])\n",
    "plt.title(\"POTime Series\")\n",
    "plt.xlabel(\"Scan number\")\n",
    "plt.ylabel(\"non-Normalized signal\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps masker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "pre_imgs = [nib.load(img) for img in pre_data]\n",
    "resampled_series = pre_imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import concat_imgs, mean_img, resample_to_img\n",
    "from nilearn.plotting import plot_epi, plot_roi, plot_stat_map\n",
    "from nilearn.maskers import NiftiMasker\n",
    "def check_masker_fit(data, masker):\n",
    "    # print basic information on the dataset\n",
    "    print(\"First functional nifti image (4D) is located \" f\"at: {data}\")\n",
    "\n",
    "    filename = data\n",
    "    mean_im = mean_img(filename)\n",
    "    plot_epi(mean_im, title=\"Mean EPI image\")\n",
    "\n",
    "    masker.fit(data)\n",
    "    print(\"Masker fit done, see html report!\")\n",
    "    report = masker.generate_report()\n",
    "    #report.save_as_html(\"masker_report.html\")\n",
    "\n",
    "    # plot the mask\n",
    "    plot_roi(masker.mask_img_, mean_im, title=\"Mask\")\n",
    "masker = NiftiMasker(standardize=True, detrend=True, verbose=5)\n",
    "check_masker_fit(data.post_hyp[1],masker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D slice to show alignment and background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import resample_img, index_img\n",
    "img = index_img(pre_data[0],1)\n",
    "img = resample_img(img, target_affine =index_img(pre_data[0],1).affine , interpolation = 'nearest')\n",
    "plot_roi(img, title = 'mask')\n",
    "plot_epi(img, bg_img = mean_data_mask, title = 'mask')\n",
    "print(img.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. checking affines from 4D nifti files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from nilearn.image import index_img\n",
    "import numpy as np\n",
    "#\n",
    "#im = index_img(im, 0)\n",
    "#print(im.shape, im.header.get_zooms(), im.get_fdata().max(), im.get_fdata().min(), im.affine)\n",
    "\n",
    "def check_affines(im):\n",
    "    compare = []\n",
    "    for i in range(im.shape[-1]):\n",
    "        aff = np.array(index_img(im, i).affine)\n",
    "        compare.append(aff)\n",
    "        if i > 0:\n",
    "            if (aff == compare[i-1]).all() == False:\n",
    "                print('Error, not same affines', i, aff, compare[i-1])\n",
    "                break\n",
    "def check_4D_affines(im):\n",
    "    '''\n",
    "    im : list of 4D images\n",
    "    \n",
    "    im is a list of 4D images\n",
    "    check if all affines are the same\n",
    "    for each subject\n",
    "    '''\n",
    "    compare = []\n",
    "    for i in range(len(im)):\n",
    "        if type(im[i]) == str:\n",
    "            im[i] = nib.load(im[i])\n",
    "            aff = np.array(nib.load(im[i]).affine)\n",
    "        else:\n",
    "            aff = np.array(im[i].affine)\n",
    "        print(aff)\n",
    "        compare.append(aff)\n",
    "        if i > 0:\n",
    "            if (aff == compare[i-1]).all() == False:\n",
    "                print('Error, not same affines for all subjects', i, aff, compare[i-1])\n",
    "                break \n",
    "    \n",
    "def check_shape(images_list):\n",
    "    compare = []\n",
    "    for i in range(len(images_list)):\n",
    "        sh = np.array(index_img(images_list, i).shape[-1])\n",
    "        compare.append(sh)\n",
    "        if i > 0:\n",
    "            if (sh == compare[i-1]).all() == False:\n",
    "                print('Error, not same shape for all subjects', i, sh, compare[i-1])\n",
    "                break\n",
    "    print('------------------')\n",
    "\n",
    "check_shape(func_pre[1])\n",
    "check_4D_affines(func_pre)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. resampling affine and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from nilearn.image import mean_img\n",
    "\n",
    "m_im = mean_img(func_pre)\n",
    "print('mean affine', m_im.affine)\n",
    "plot_roi(m_im, title = 'mask')\n",
    "plotting.view_img(m_im, threshold=None)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " when target_affine = reference_affine, the shape of the resampled image is NOT the same as the reference image. Have to specify mask_strategy =  ref_img.shape[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "mean_all = mean_img(func_post + func_pre)\n",
    "print(mean_all.affine, mean_all.shape)\n",
    "(mean_all.affine == nib.load(func_post[1]).affine).all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling to mean_img from all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import resample_to_img\n",
    "resampled = []\n",
    "all_files = func_pre + func_post\n",
    "ref_img = mean_all # with affine of first image used to fit mean_img\n",
    "for i in range(len(all_files)):\n",
    "    resampled.append(resample_to_img(all_files[i], ref_img, interpolation='continuous'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_resampled = mean_img(resampled)\n",
    "mean_resampled.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling to MNI space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mni_resampled = []\n",
    "all_files = func_pre\n",
    "ref_img = data_mask # with affine of first image used to fit mean_img\n",
    "for i in range(len(all_files)):\n",
    "    mni_resampled.append(resample_to_img(all_files[i], ref_img, interpolation='continuous'))\n",
    "mean_mni = mean_img(mni_resampled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Comparing resampled-to-img.affine VS resampled-to-mniMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_resampled = mean_img(resampled)    \n",
    "plot_roi(mean_resampled, title = 'mean_resampled', colorbar=True)\n",
    "plot_epi(mean_resampled, title = 'mean_resampled',colorbar=True)\n",
    "plotting.view_img(mean_resampled, threshold=None)\n",
    "plot_epi(mean_mni, title = 'mean resampled to mni mean mask',colorbar=True)\n",
    "plot_roi(mean_mni, title = 'mean resampled to mni mean mask',colorbar=True)\n",
    "plotting.view_img(mean_mni, threshold=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling with masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.image import resample_to_img\n",
    "import nibabel as nib\n",
    "\n",
    "ref_img = data_mask\n",
    "all_files = pre_data[0]\n",
    "resample_strategy = 'masker'\n",
    "args = {}\n",
    "resampled_series = None\n",
    "if resample_strategy == 'masker':\n",
    "    # using masker to resample all images to the same shape\n",
    "    voxel_masker = NiftiMasker(target_affine= ref_img.affine,target_shape = ref_img.shape, t_r = 3, high_pass = 0.1, detrend = True,mask_strategy = 'background',mask_args = args, standardize='zscore_sample')\n",
    "    voxel_masker.fit(all_files)\n",
    "    masked_img = voxel_masker.transform(all_files)\n",
    "    print('ref_img.shape :{}, masked image shape : {}, inverse transformed img shape {}'.format(ref_img.shape, masked_img.shape,voxel_masker.inverse_transform(masked_img).shape))  \n",
    "    resampled_series = [voxel_masker.inverse_transform(im) for im in masked_img]\n",
    "\n",
    "    print('ref_img.shape :{}, resampled imgages shapes {}'.format(ref_img.shape, [s.shape for s in resampled_series]))\n",
    "    check_4D_affines(resampled_series)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing an EPI mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.plotting import plot_epi, plot_roi\n",
    "from nilearn.masking import compute_epi_mask, compute_multi_epi_mask\n",
    "multi_epi_mask = compute_multi_epi_mask(resampled_series, opening = 1, connected = True, exclude_zeros = True, \n",
    "                                       upper_cutoff = 0.95, lower_cutoff = 0.2)\n",
    "plot_roi(multi_epi_mask, bg_img = m_im)\n",
    "\n",
    "# fitting nifi masker on one subject to generate report\n",
    "nm = NiftiMasker(mask_img = multi_epi_mask)\n",
    "nm.fit(resampled_series[2])\n",
    "nm.generate_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Maskers for resampled series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NiftiMasker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_resampled = mean_img(resampled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing mean resampled vs mean resampled to MNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import concat_imgs\n",
    "for img in [resampled, mni_resampled]:\n",
    "    concat = mean_img(concat_imgs(img))\n",
    "    print(concat.shape)\n",
    "    plot_roi(concat, title = 'mask')\n",
    "    v = plotting.view_img(concat, threshold=None)\n",
    "    v"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Masker on resampled data, no mask_img on single-sub timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import MultiNiftiMasker, NiftiMasker\n",
    "m = NiftiMasker(mask_strategy = 'whole-brain-template', t_r = 3, smoothing_fwhm=6).fit(resampled[0])\n",
    "t = m.transform(resampled[0])\n",
    "trans_mean_mask = m.inverse_transform(t)\n",
    "plot_roi(mean_img(resampled[1]), title = 'mean data on mni background')\n",
    "plot_roi(mean_img(trans_mean_mask), title = 'transfomed mean img')\n",
    "plot_roi(m.mask_img_, title = 'computed mask')\n",
    "m.generate_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_mean_mask[0].affine == mni_resampled[0].affine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.b with 'epi' strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import MultiNiftiMasker, NiftiMasker\n",
    "m = NiftiMasker(mask_strategy = 'epi', t_r = 3, smoothing_fwhm=6).fit(resampled[0])\n",
    "t = m.transform(resampled[0])\n",
    "trans_mean_mask = m.inverse_transform(t)\n",
    "plot_roi(mean_img(trans_mean_mask), title = 'mean transformed imgs')\n",
    "plot_roi(m.mask_img_, title = 'computed mask')\n",
    "m.generate_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Masker on MNI-resampled data, with mask_img on single-sub timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import MultiNiftiMasker, NiftiMasker\n",
    "\n",
    "m = NiftiMasker(mask_strategy = 'whole-brain-template', t_r = 3, smoothing_fwhm=6).fit(mni_resampled[0])\n",
    "t = m.transform(mni_resampled[0], confounds = data.confounds_pre_hyp + data.confounds_post_hyp)\n",
    "trans_mean_mask = m.inverse_transform(t)\n",
    "plot_roi(mean_img(trans_mean_mask), title = 'mean transformed imgs')\n",
    "plot_roi(m.mask_img_, title = 'computed mask')\n",
    "m.generate_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Masker on MNI-resampled data, with binarized mean_data_mask(MNI) on single-sub timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import binarize_img\n",
    "bin_mni_mask = binarize_img(mean_data_mask)\n",
    "plot_roi(bin_mni_mask, title = 'binarized mni mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import MultiNiftiMasker, NiftiMasker\n",
    "\n",
    "m = NiftiMasker(mask_img = bin_mni_mask, mask_strategy = 'whole-brain-template', t_r = 3, smoothing_fwhm=6).fit(mni_resampled[0])\n",
    "t = m.transform(mni_resampled[0])\n",
    "trans_mean_mask = m.inverse_transform(t)\n",
    "plot_roi(mean_img(trans_mean_mask), title = 'mean transformed imgs')\n",
    "plot_roi(m.mask_img_, title = 'computed mask')\n",
    "m.generate_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Masker on resampled data, with binarized mean_data_mask(MNI) on single-sub timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import MultiNiftiMasker, NiftiMasker\n",
    "\n",
    "m = NiftiMasker(mask_img = bin_mni_mask, mask_strategy = 'whole-brain-template', t_r = 3, smoothing_fwhm=6).fit(resampled[0])\n",
    "t = m.transform(resampled[0])\n",
    "trans_mean_mask = m.inverse_transform(t)\n",
    "plot_roi(mean_img(trans_mean_mask), title = 'mean transformed imgs')\n",
    "plot_roi(m.mask_img_, title = 'computed mask')\n",
    "m.generate_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Comparing 'epi' vs 'background' strategies on  multisubjects resampled data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 'epi' --> cuts a little the data, but removes out of brain ring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import MultiNiftiMasker, NiftiMasker\n",
    "\n",
    "mnm = MultiNiftiMasker(mask_strategy = 'epi', t_r = 3, smoothing_fwhm=6).fit(resampled)\n",
    "t = mnm.transform(resampled, confounds = data.confounds_pre_hyp + data.confounds_post_hyp)\n",
    "trans_mean_mask = mnm.inverse_transform(t)\n",
    "plot_roi(mean_img(resampled),bg_img = mean_all, title = 'mean imgs', colorbar=True)\n",
    "plot_roi(mean_img(trans_mean_mask),bg_img = mean_all, title = 'mean transformed imgs', colorbar=True)\n",
    "plot_roi(mnm.mask_img_,bg_img=mean_all, title = 'computed mask',  colorbar=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 'background' --> keeps the data, but keeps out of brain ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import MultiNiftiMasker, NiftiMasker\n",
    "\n",
    "m = MultiNiftiMasker(mask_strategy = 'background',t_r = 3, smoothing_fwhm=6).fit(resampled)\n",
    "t = m.transform(resampled, confounds = data.confounds_pre_hyp + data.confounds_post_hyp)\n",
    "trans_mean_mask = m.inverse_transform(t)\n",
    "plot_roi(mean_img(resampled),bg_img = mean_all, title = 'mean imgs', colorbar=True)\n",
    "plot_roi(mean_img(trans_mean_mask),bg_img = mean_all, title = 'mean transformed imgs', colorbar=True)\n",
    "plot_roi(m.mask_img_, title = 'computed mask',  colorbar=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing masker.transform vs masker.transform_imgs : Appear to be the same at the 5D level!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(trans_[0].shape,transf_imgs[0].shape)\n",
    "(trans_[0] == transf_imgs[0]).all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming single subject 4D data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Maps masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiMapsMasker, MultiNiftiMapsMasker  \n",
    "\n",
    "masker = NiftiMapsMasker(\n",
    "            maps_img=atlas,mask_img = mnm.mask_img_,t_r=3,smoothing_fwhm=6,standardize=\"zscore_sample\",verbose=5,resampling_target=\"data\",)\n",
    "masker.fit(resampled[0])\n",
    "\n",
    "time_series = masker.transform(resampled[0], confounds=data.confounds_pre_hyp[0])\n",
    "plot_roi(\n",
    "    masker.mask_img_,bg_img = mean_img(atlas), title=\"Maps mask from multi-masker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from nilearn.image import index_img\n",
    "from nilearn.plotting import find_xyz_cut_coords\n",
    "\n",
    "# Showing region extraction results using 4D maps visualization tool\n",
    "plotting.plot_prob_atlas(\n",
    "    atlas,\n",
    "    display_mode=\"z\",\n",
    "    cut_coords=1,\n",
    "    view_type=\"contours\",\n",
    "    title=\"Regions extracted.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiMapsMasker, MultiNiftiMapsMasker  \n",
    "\n",
    "masker = NiftiMapsMasker(\n",
    "            maps_img=atlas,\n",
    "            mask_img = mean_data_mask,\n",
    "            t_r=3,\n",
    "            smoothing_fwhm=6,\n",
    "            standardize=\"zscore_sample\",\n",
    "            verbose=5,\n",
    "            resampling_target=\"mask\",\n",
    "        )\n",
    "masker.fit(all_files[0])\n",
    "\n",
    "time_series = masker.transform(resampled[0], confounds=data.confounds_pre_hyp[0])\n",
    "plot_roi(\n",
    "    masker.mask_img_,bg_img = mean_img(atlas), title=\"Maps mask from multi-masker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = masker.generate_report(displayed_maps=[2, 6, 7, 16, 21, 30, 40,50,60])\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiMapsMasker, MultiNiftiMapsMasker  \n",
    "\n",
    "masker = NiftiMapsMasker(\n",
    "            maps_img=atlas,\n",
    "            t_r=3,\n",
    "            smoothing_fwhm=6,\n",
    "            standardize=\"zscore_sample\",\n",
    "            verbose=5,\n",
    "            resampling_target=\"data\",\n",
    "        )\n",
    "masker.fit(resampled[0])\n",
    "\n",
    "time_series = masker.transform(resampled[0], confounds=data.confounds_pre_hyp[0])\n",
    "plot_roi(\n",
    "    masker.mask_img_,bg_img = mean_img(atlas), title=\"Maps mask from multi-masker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.generate_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. labeled masker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yeo17 atlas (labeled atlas vs maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(func)\n",
    "\n",
    "yeoatlas, atlas_labels,atlas_name, confounds = func.load_choose_atlas('yeo_17', bilat=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roi(mean_resampled, bg_img = resample_to_img(mean_resampled, yeoatlas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for matching labels/values\n",
    "import numpy as np\n",
    "print(atlas_labels, np.unique(yeoatlas.get_fdata(), return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiLabelsMasker, MultiNiftiLabelsMasker\n",
    "\n",
    "lm = NiftiLabelsMasker(labels_img = yeoatlas, mask_img= bin_mni_mask, labels = atlas_labels,resampling_target = 'data', standardize = 'zscore_sample', verbose=0)\n",
    "lm.fit(mni_resampled[1])\n",
    "lm.generate_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "atlas = datasets.fetch_atlas_msdl()\n",
    "# Loading atlas image stored in 'maps'\n",
    "atlas_filename = atlas[\"maps\"]\n",
    "# Loading atlas data stored in 'labels'\n",
    "\n",
    "from nilearn.maskers import NiftiMapsMasker, MultiNiftiMapsMasker  \n",
    "\n",
    "masker = NiftiMapsMasker(\n",
    "            maps_img=atlas_filename,\n",
    "            standardize=\"zscore_sample\",\n",
    "            verbose=5,\n",
    "            resampling_target=\"data\",\n",
    "        )\n",
    "masker.fit(resampled[0])\n",
    "\n",
    "time_series = masker.transform(resampled[0], confounds=data.confounds_pre_hyp[0])\n",
    "#plot_roi(\n",
    "    #masker.mask_img_,bg_img = mean_img(atlas), title=\"Maps mask from multi-masker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.generate_report(displayed_maps=[2, 6, 7,])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> MapsMasker with mask from MultiMasker ('epi' strategy)\n",
    "--> not aligned with atlas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiMapsMasker, MultiNiftiMapsMasker  \n",
    "\n",
    "masker = MultiNiftiMapsMasker(\n",
    "            maps_img=atlas,\n",
    "            t_r=3,\n",
    "            smoothing_fwhm=6,\n",
    "            standardize=\"zscore_sample\",\n",
    "            verbose=5,\n",
    "            resampling_target=\"data\",\n",
    "        )\n",
    "masker.fit(resampled)\n",
    "results['pre_series'] = [masker.transform(ts, confounds = cf) for ts, cf in zip(resampled, data.confounds_pre_hyp)]\n",
    "inv = [masker.inverse_transform(ts) for ts in results['pre_series']]\n",
    "plot_roi(\n",
    "    masker.mask_img_,bg_img = mean_img(atlas), title=\"Maps mask from multi-masker\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiMapsMasker, MultiNiftiMapsMasker  \n",
    "\n",
    "masker = MultiNiftiMapsMasker(\n",
    "            maps_img=atlas,\n",
    "            t_r=3,\n",
    "            smoothing_fwhm=6,\n",
    "            standardize=\"zscore_sample\",\n",
    "            verbose=5,\n",
    "            resampling_target=\"data\",\n",
    "        )\n",
    "masker.fit(mni_resampled)\n",
    "results['pre_series'] = [masker.transform(ts, confounds = cf) for ts, cf in zip(mni_resampled, data.confounds_pre_hyp)]\n",
    "inv = [masker.inverse_transform(ts) for ts in results['pre_series']]\n",
    "plot_roi(\n",
    "    masker.mask_img_,bg_img = mean_img(atlas), title=\"Maps mask from multi-masker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['pre_series'][0].shape\n",
    "inv[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nilearn.maskers import MultiNiftiMapsMasker   \n",
    "\n",
    "multi_mapsmasker = MultiNiftiMapsMasker(\n",
    "            maps_img=atlas,\n",
    "            mask_img=voxel_masker.mask_img_,\n",
    "            t_r=3,\n",
    "            smoothing_fwhm=6,\n",
    "            standardize=\"zscore_sample\",\n",
    "            verbose=5,\n",
    "            resampling_target=\"data\",\n",
    "        )\n",
    "multi_mapsmasker.fit(resampled_series)\n",
    "print(multi_mapsmasker.mask_img_.shape, multi_mapsmasker.transform(resampled_series[0]).shape)\n",
    "samp_multimaps0 = multi_mapsmasker.transform(resampled_series[0])\n",
    "plot_roi(\n",
    "    masker.mask_img_,bg_img = m_im, title=\"Maps mask from multi-masker\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_mapsmasker.generate_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing single img transform from MultiMaps vs maps : gives same output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(samp_maps0.shape, samp_multimaps0.shape)\n",
    "(samp_maps0 == samp_multimaps0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_prob_atlas\n",
    "\n",
    "plot_prob_atlas(atlas, bg_img = voxel_masker.mask_img_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sphere-ROI correlation to plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(results[\"pre_series\"][0].shape, results[\"seed_pre_series\"][0].shape)\n",
    "[seed_masker.transform(ts) for ts in resampled_series]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"voxel_pre_series\"] = [mnm.transform(ts) for ts in resampled_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from nilearn.maskers import NiftiSpheresMasker\n",
    "\n",
    "sphere_coord = [(54, -28, 26)]\n",
    "seed_masker = NiftiSpheresMasker(\n",
    "    sphere_coord, radius=8, standardize=\"zscore_sample\"\n",
    ")\n",
    "\n",
    "seed_masker.fit(func_asl)\n",
    "\n",
    "results[\"seed_pre_series\"] = [seed_masker.transform(ts) for ts in resampled_series]\n",
    "results[\"seed_to_pre_correlations\"] = [\n",
    "        (np.dot(brain_time_series.T, seed_time_series) / seed_time_series.shape[0])\n",
    "        for brain_time_series, seed_time_series in zip(\n",
    "            results[\"voxel_pre_series\"], results[\"seed_pre_series\"]\n",
    "        )\n",
    "    ]    \n",
    "\n",
    "results[\"mean_seed_pre_connectome\"] = np.mean(\n",
    "        results[\"seed_to_pre_correlations\"], axis=0\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"mean_seed_pre_connectome\"].T.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.datasets import fetch_atlas_yeo_2011\n",
    "\n",
    "# Fetch the Yeo-17 atlas\n",
    "atlas = fetch_atlas_yeo_2011()\n",
    "\n",
    "# Access the region labels\n",
    "region_labels = atlas['labels']\n",
    "\n",
    "# Print the region labels\n",
    "for label in region_labels:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed_to_voxel_correlations_img = mnm.inverse_transform(\n",
    "    results[\"mean_seed_pre_connectome\"].T\n",
    ")\n",
    "\n",
    "display = plotting.plot_stat_map(\n",
    "    seed_to_voxel_correlations_img,\n",
    "    threshold=0.5,\n",
    "    vmax=1,\n",
    "    cut_coords=sphere_coord[0],\n",
    "    title=\"Seed-to-voxel correlation (OP seed)\",\n",
    ")\n",
    "display.add_markers(\n",
    "    marker_coords=sphere_coord[0], marker_color=\"g\", marker_size=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.datasets import fetch_miyawaki2008\n",
    "\n",
    "dataset = fetch_miyawaki2008()\n",
    "\n",
    "# training data starts after the first 12 files\n",
    "fmri_random_runs_filenames = dataset.func[12:]\n",
    "stimuli_random_runs_filenames = dataset.label[12:]\n",
    "\n",
    "# training data starts after the first 12 files\n",
    "fmri_random_runs_filenames = dataset.func[12:]\n",
    "stimuli_random_runs_filenames = dataset.label[12:]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nilearn.maskers import MultiNiftiMasker\n",
    "\n",
    "masker = MultiNiftiMasker(\n",
    "    mask_img=dataset.mask, detrend=True, standardize=\"zscore_sample\"\n",
    ")\n",
    "masker.fit()\n",
    "fmri_data = masker.transform(fmri_random_runs_filenames)\n",
    "\n",
    "# shape of the binary (i.e. black and wihte values) image in pixels\n",
    "stimulus_shape = (10, 10)\n",
    "\n",
    "# We load the visual stimuli from csv files\n",
    "stimuli = []\n",
    "for stimulus_run in stimuli_random_runs_filenames:\n",
    "    stimuli.append(\n",
    "        np.reshape(\n",
    "            np.loadtxt(stimulus_run, dtype=int, delimiter=\",\"),\n",
    "            (-1,) + stimulus_shape,\n",
    "            order=\"F\",\n",
    "        )\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "table = np.array([[1, 10,  1, 11],\n",
    "                  [2, 21,  2, 20],\n",
    "                  [3, 30, 3, 31],\n",
    "                  [4, 41, 4, 40]])\n",
    "table_0 = table[table>10]\n",
    "print(table_0)\n",
    "print(table[table<10 & table%2!=0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
