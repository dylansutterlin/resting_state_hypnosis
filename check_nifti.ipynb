{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_con import con_matrix\n",
    "import os\n",
    "from scripts import func\n",
    "from nilearn.image import mean_img\n",
    "from nilearn import plotting\n",
    "import glob as glob\n",
    "from nilearn.plotting import plot_img, plot_epi, plot_roi, plot_stat_map\n",
    "import importlib\n",
    "importlib.reload(func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --Data--\n",
    "\n",
    "data_dir =r'E:\\Users\\Dylan\\Desktop\\UdeM_H22\\E_PSY3008\\data_desmartaux\\2sub_ASL_data'\n",
    "save_base = r'C:\\Users\\Dylan\\Desktop\\UM_Bsc_neurocog\\E22\\Projet_Ivado_rainvillelab\\results'\n",
    "atlas_name=\"difumo64\"\n",
    "atlas_type=\"maps\"\n",
    "data = func.load_data(data_dir)\n",
    "conditions = [\"pre_hyp\", \"post_hyp\", \"contrast\"]\n",
    "func_pre = data.func_pre_hyp\n",
    "func_post = data.func_post_hyp\n",
    "all_files = func_pre + func_post\n",
    "results = dict(pre_series=list(), post_series=list())\n",
    "\n",
    "atlas, atlas_labels,atlas_name, confounds = func.load_choose_atlas(atlas_name, bilat=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean data masks on mean anat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import  mean_img\n",
    "mean_anat = mean_img(data.anat)\n",
    "mean_data_mask = mean_img([data.pre_masks, data.post_masks])\n",
    "plotting.plot_roi(mean_data_mask, bg_img=mean_anat, cmap='Paired')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "pre_imgs = [nib.load(img) for img in pre_data]\n",
    "resampled_series = pre_imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import concat_imgs, mean_img, resample_to_img\n",
    "from nilearn.plotting import plot_epi, plot_roi, plot_stat_map\n",
    "from nilearn.maskers import NiftiMasker\n",
    "def check_masker_fit(data, masker):\n",
    "    # print basic information on the dataset\n",
    "    print(\"First functional nifti image (4D) is located \" f\"at: {data}\")\n",
    "\n",
    "    filename = data\n",
    "    mean_im = mean_img(filename)\n",
    "    plot_epi(mean_im, title=\"Mean EPI image\")\n",
    "\n",
    "    masker.fit(data)\n",
    "    print(\"Masker fit done, see html report!\")\n",
    "    report = masker.generate_report()\n",
    "    #report.save_as_html(\"masker_report.html\")\n",
    "\n",
    "    # plot the mask\n",
    "    plot_roi(masker.mask_img_, mean_im, title=\"Mask\")\n",
    "masker = NiftiMasker(standardize=True, detrend=True, verbose=5)\n",
    "check_masker_fit(data.post_hyp[1],masker)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean mask in MNI space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meanASL_4D_before : No\n",
    "wmeanCBF_0_srASL_4D_before : yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "file = r'E:\\Users\\Dylan\\Desktop\\UdeM_H22\\E_PSY3008\\data_desmartaux\\2sub_ASL_data\\APM_08_H2\\01-PCASL_before_hypnosis\\wcbf_0_srASL_4D_before_4D.nii'\n",
    "data_mask = nib.load(file)\n",
    "plot_epi(data_mask, title=\"Mean EPI image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = data.func_pre_hyp[1]\n",
    "test_img = nib.load(test_img)\n",
    "new_img = resample_to_img(index_img(test_img,0), data_mask, interpolation='nearest')\n",
    "plot_roi(new_img, title = 'resampled to : wmeanCBF_0_srASL_4D_before.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r'E:\\Users\\Dylan\\Desktop\\UdeM_H22\\E_PSY3008\\data_desmartaux\\2sub_ASL_data\\APM_08_H2\\01-PCASL_before_hypnosis\\wcbf_0_srASL_4D_before_4D.nii'\n",
    "mean_data_mask = nib.load(file)\n",
    "plot_roi(mean_data_mask, title = 'mask')\n",
    "plot_epi(mean_data_mask, title = 'mask')\n",
    "print(data_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D slice to show alignment and background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import resample_img, index_img\n",
    "img = index_img(pre_data[0],1)\n",
    "img = resample_img(img, target_affine =index_img(pre_data[0],1).affine , interpolation = 'nearest')\n",
    "plot_roi(img, title = 'mask')\n",
    "plot_epi(img, bg_img = mean_data_mask, title = 'mask')\n",
    "print(img.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. checking affines from 4D nifti files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from nilearn.image import index_img\n",
    "import numpy as np\n",
    "#\n",
    "#im = index_img(im, 0)\n",
    "#print(im.shape, im.header.get_zooms(), im.get_fdata().max(), im.get_fdata().min(), im.affine)\n",
    "\n",
    "def check_affines(im):\n",
    "    compare = []\n",
    "    for i in range(im.shape[-1]):\n",
    "        aff = np.array(index_img(im, i).affine)\n",
    "        compare.append(aff)\n",
    "        if i > 0:\n",
    "            if (aff == compare[i-1]).all() == False:\n",
    "                print('Error, not same affines', i, aff, compare[i-1])\n",
    "                break\n",
    "def check_4D_affines(im):\n",
    "    '''\n",
    "    im : list of 4D images\n",
    "    \n",
    "    im is a list of 4D images\n",
    "    check if all affines are the same\n",
    "    for each subject\n",
    "    '''\n",
    "    compare = []\n",
    "    for i in range(len(im)):\n",
    "        if type(im[i]) == str:\n",
    "            im[i] = nib.load(im[i])\n",
    "            aff = np.array(nib.load(im[i]).affine)\n",
    "        else:\n",
    "            aff = np.array(im[i].affine)\n",
    "        print(aff)\n",
    "        compare.append(aff)\n",
    "        if i > 0:\n",
    "            if (aff == compare[i-1]).all() == False:\n",
    "                print('Error, not same affines for all subjects', i, aff, compare[i-1])\n",
    "                break \n",
    "    \n",
    "def check_shape(images_list):\n",
    "    compare = []\n",
    "    for i in range(len(images_list)):\n",
    "        sh = np.array(index_img(images_list, i).shape[-1])\n",
    "        compare.append(sh)\n",
    "        if i > 0:\n",
    "            if (sh == compare[i-1]).all() == False:\n",
    "                print('Error, not same shape for all subjects', i, sh, compare[i-1])\n",
    "                break\n",
    "    print('------------------')\n",
    "\n",
    "check_shape(func_pre[1])\n",
    "check_4D_affines(func_pre)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. resampling affine and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from nilearn.image import mean_img\n",
    "\n",
    "m_im = mean_img(func_pre)\n",
    "print('mean affine', m_im.affine)\n",
    "plot_roi(m_im, title = 'mask')\n",
    "plotting.view_img(m_im, threshold=None)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " when target_affine = reference_affine, the shape of the resampled image is NOT the same as the reference image. Have to specify mask_strategy =  ref_img.shape[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "mean_all = mean_img(func_post + func_pre)\n",
    "print(mean_all.affine, mean_all.shape)\n",
    "(mean_all.affine == nib.load(func_post[1]).affine).all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling to mean_img from all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import resample_to_img\n",
    "resampled = []\n",
    "all_files = func_pre + func_post\n",
    "ref_img = mean_all # with affine of first image used to fit mean_img\n",
    "for i in range(len(all_files)):\n",
    "    resampled.append(resample_to_img(all_files[i], ref_img, interpolation='continuous'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_resampled = mean_img(resampled)\n",
    "mean_resampled.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling to MNI space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mni_resampled = []\n",
    "all_files = func_pre\n",
    "ref_img = data_mask # with affine of first image used to fit mean_img\n",
    "for i in range(len(all_files)):\n",
    "    mni_resampled.append(resample_to_img(all_files[i], ref_img, interpolation='continuous'))\n",
    "mean_mni = mean_img(mni_resampled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Comparing resampled-to-img.affine VS resampled-to-mniMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_resampled = mean_img(resampled)    \n",
    "plot_roi(mean_resampled, title = 'mean_resampled', colorbar=True)\n",
    "plot_epi(mean_resampled, title = 'mean_resampled',colorbar=True)\n",
    "plotting.view_img(mean_resampled, threshold=None)\n",
    "plot_epi(mean_mni, title = 'mean resampled to mni mean mask',colorbar=True)\n",
    "plot_roi(mean_mni, title = 'mean resampled to mni mean mask',colorbar=True)\n",
    "plotting.view_img(mean_mni, threshold=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling with masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.image import resample_to_img\n",
    "import nibabel as nib\n",
    "\n",
    "ref_img = data_mask\n",
    "all_files = pre_data[0]\n",
    "resample_strategy = 'masker'\n",
    "args = {}\n",
    "resampled_series = None\n",
    "if resample_strategy == 'masker':\n",
    "    # using masker to resample all images to the same shape\n",
    "    voxel_masker = NiftiMasker(target_affine= ref_img.affine,target_shape = ref_img.shape, t_r = 3, high_pass = 0.1, detrend = True,mask_strategy = 'background',mask_args = args, standardize='zscore_sample')\n",
    "    voxel_masker.fit(all_files)\n",
    "    masked_img = voxel_masker.transform(all_files)\n",
    "    print('ref_img.shape :{}, masked image shape : {}, inverse transformed img shape {}'.format(ref_img.shape, masked_img.shape,voxel_masker.inverse_transform(masked_img).shape))  \n",
    "    resampled_series = [voxel_masker.inverse_transform(im) for im in masked_img]\n",
    "\n",
    "    print('ref_img.shape :{}, resampled imgages shapes {}'.format(ref_img.shape, [s.shape for s in resampled_series]))\n",
    "    check_4D_affines(resampled_series)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing an EPI mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.plotting import plot_epi, plot_roi\n",
    "from nilearn.masking import compute_epi_mask, compute_multi_epi_mask\n",
    "multi_epi_mask = compute_multi_epi_mask(resampled_series, opening = 1, connected = True, exclude_zeros = True, \n",
    "                                       upper_cutoff = 0.95, lower_cutoff = 0.2)\n",
    "plot_roi(multi_epi_mask, bg_img = m_im)\n",
    "\n",
    "# fitting nifi masker on one subject to generate report\n",
    "nm = NiftiMasker(mask_img = multi_epi_mask)\n",
    "nm.fit(resampled_series[2])\n",
    "nm.generate_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Maskers for resampled series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NiftiMasker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_resampled = mean_img(resampled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing mean resampled vs mean resampled to MNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import concat_imgs\n",
    "for img in [resampled, mni_resampled]:\n",
    "    concat = mean_img(concat_imgs(img))\n",
    "    print(concat.shape)\n",
    "    plot_roi(concat, title = 'mask')\n",
    "    v = plotting.view_img(concat, threshold=None)\n",
    "    v"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Masker on resampled data, no mask_img on single-sub timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import MultiNiftiMasker, NiftiMasker\n",
    "m = NiftiMasker(mask_strategy = 'whole-brain-template', t_r = 3, smoothing_fwhm=6).fit(resampled[0])\n",
    "t = m.transform(resampled[0])\n",
    "trans_mean_mask = m.inverse_transform(t)\n",
    "plot_roi(mean_img(resampled[1]), title = 'mean data on mni background')\n",
    "plot_roi(mean_img(trans_mean_mask), title = 'transfomed mean img')\n",
    "plot_roi(m.mask_img_, title = 'computed mask')\n",
    "m.generate_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_mean_mask[0].affine == mni_resampled[0].affine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.b with 'epi' strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import MultiNiftiMasker, NiftiMasker\n",
    "m = NiftiMasker(mask_strategy = 'epi', t_r = 3, smoothing_fwhm=6).fit(resampled[0])\n",
    "t = m.transform(resampled[0])\n",
    "trans_mean_mask = m.inverse_transform(t)\n",
    "plot_roi(mean_img(trans_mean_mask), title = 'mean transformed imgs')\n",
    "plot_roi(m.mask_img_, title = 'computed mask')\n",
    "m.generate_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Masker on MNI-resampled data, with mask_img on single-sub timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import MultiNiftiMasker, NiftiMasker\n",
    "\n",
    "m = NiftiMasker(mask_strategy = 'whole-brain-template', t_r = 3, smoothing_fwhm=6).fit(mni_resampled[0])\n",
    "t = m.transform(mni_resampled[0], confounds = data.confounds_pre_hyp + data.confounds_post_hyp)\n",
    "trans_mean_mask = m.inverse_transform(t)\n",
    "plot_roi(mean_img(trans_mean_mask), title = 'mean transformed imgs')\n",
    "plot_roi(m.mask_img_, title = 'computed mask')\n",
    "m.generate_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Masker on MNI-resampled data, with binarized mean_data_mask(MNI) on single-sub timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import binarize_img\n",
    "bin_mni_mask = binarize_img(mean_data_mask)\n",
    "plot_roi(bin_mni_mask, title = 'binarized mni mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import MultiNiftiMasker, NiftiMasker\n",
    "\n",
    "m = NiftiMasker(mask_img = bin_mni_mask, mask_strategy = 'whole-brain-template', t_r = 3, smoothing_fwhm=6).fit(mni_resampled[0])\n",
    "t = m.transform(mni_resampled[0])\n",
    "trans_mean_mask = m.inverse_transform(t)\n",
    "plot_roi(mean_img(trans_mean_mask), title = 'mean transformed imgs')\n",
    "plot_roi(m.mask_img_, title = 'computed mask')\n",
    "m.generate_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Masker on resampled data, with binarized mean_data_mask(MNI) on single-sub timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import MultiNiftiMasker, NiftiMasker\n",
    "\n",
    "m = NiftiMasker(mask_img = bin_mni_mask, mask_strategy = 'whole-brain-template', t_r = 3, smoothing_fwhm=6).fit(resampled[0])\n",
    "t = m.transform(resampled[0])\n",
    "trans_mean_mask = m.inverse_transform(t)\n",
    "plot_roi(mean_img(trans_mean_mask), title = 'mean transformed imgs')\n",
    "plot_roi(m.mask_img_, title = 'computed mask')\n",
    "m.generate_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Comparing 'epi' vs 'background' strategies on  multisubjects resampled data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 'epi' --> cuts a little the data, but removes out of brain ring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import MultiNiftiMasker, NiftiMasker\n",
    "\n",
    "mnm = MultiNiftiMasker(mask_strategy = 'epi', t_r = 3, smoothing_fwhm=6).fit(resampled)\n",
    "t = mnm.transform(resampled, confounds = data.confounds_pre_hyp + data.confounds_post_hyp)\n",
    "trans_mean_mask = mnm.inverse_transform(t)\n",
    "plot_roi(mean_img(resampled),bg_img = mean_all, title = 'mean imgs', colorbar=True)\n",
    "plot_roi(mean_img(trans_mean_mask),bg_img = mean_all, title = 'mean transformed imgs', colorbar=True)\n",
    "plot_roi(mnm.mask_img_,bg_img=mean_all, title = 'computed mask',  colorbar=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 'background' --> keeps the data, but keeps out of brain ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import MultiNiftiMasker, NiftiMasker\n",
    "\n",
    "m = MultiNiftiMasker(mask_strategy = 'background',t_r = 3, smoothing_fwhm=6).fit(resampled)\n",
    "t = m.transform(resampled, confounds = data.confounds_pre_hyp + data.confounds_post_hyp)\n",
    "trans_mean_mask = m.inverse_transform(t)\n",
    "plot_roi(mean_img(resampled),bg_img = mean_all, title = 'mean imgs', colorbar=True)\n",
    "plot_roi(mean_img(trans_mean_mask),bg_img = mean_all, title = 'mean transformed imgs', colorbar=True)\n",
    "plot_roi(m.mask_img_, title = 'computed mask',  colorbar=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing masker.transform vs masker.transform_imgs : Appear to be the same at the 5D level!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(trans_[0].shape,transf_imgs[0].shape)\n",
    "(trans_[0] == transf_imgs[0]).all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming single subject 4D data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Maps masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiMapsMasker, MultiNiftiMapsMasker  \n",
    "\n",
    "masker = NiftiMapsMasker(\n",
    "            maps_img=atlas,\n",
    "            mask_img = mnm.mask_img_,\n",
    "            t_r=3,\n",
    "            smoothing_fwhm=6,\n",
    "            standardize=\"zscore_sample\",\n",
    "            verbose=5,\n",
    "            resampling_target=\"data\",\n",
    "        )\n",
    "masker.fit(resampled[0])\n",
    "\n",
    "time_series = masker.transform(resampled[0], confounds=data.confounds_pre_hyp[0])\n",
    "plot_roi(\n",
    "    masker.mask_img_,bg_img = mean_img(atlas), title=\"Maps mask from multi-masker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from nilearn.image import index_img\n",
    "from nilearn.plotting import find_xyz_cut_coords\n",
    "\n",
    "# Showing region extraction results using 4D maps visualization tool\n",
    "plotting.plot_prob_atlas(\n",
    "    atlas,\n",
    "    display_mode=\"z\",\n",
    "    cut_coords=1,\n",
    "    view_type=\"contours\",\n",
    "    title=\"Regions extracted.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiMapsMasker, MultiNiftiMapsMasker  \n",
    "\n",
    "masker = NiftiMapsMasker(\n",
    "            maps_img=atlas,\n",
    "            mask_img = mean_data_mask,\n",
    "            t_r=3,\n",
    "            smoothing_fwhm=6,\n",
    "            standardize=\"zscore_sample\",\n",
    "            verbose=5,\n",
    "            resampling_target=\"mask\",\n",
    "        )\n",
    "masker.fit(all_files[0])\n",
    "\n",
    "time_series = masker.transform(resampled[0], confounds=data.confounds_pre_hyp[0])\n",
    "plot_roi(\n",
    "    masker.mask_img_,bg_img = mean_img(atlas), title=\"Maps mask from multi-masker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = masker.generate_report(displayed_maps=[2, 6, 7, 16, 21, 30, 40,50,60])\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiMapsMasker, MultiNiftiMapsMasker  \n",
    "\n",
    "masker = NiftiMapsMasker(\n",
    "            maps_img=atlas,\n",
    "            t_r=3,\n",
    "            smoothing_fwhm=6,\n",
    "            standardize=\"zscore_sample\",\n",
    "            verbose=5,\n",
    "            resampling_target=\"data\",\n",
    "        )\n",
    "masker.fit(resampled[0])\n",
    "\n",
    "time_series = masker.transform(resampled[0], confounds=data.confounds_pre_hyp[0])\n",
    "plot_roi(\n",
    "    masker.mask_img_,bg_img = mean_img(atlas), title=\"Maps mask from multi-masker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.generate_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. labeled masker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yeo17 atlas (labeled atlas vs maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(func)\n",
    "\n",
    "yeoatlas, atlas_labels,atlas_name, confounds = func.load_choose_atlas('yeo_17', bilat=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roi(mean_resampled, bg_img = resample_to_img(mean_resampled, yeoatlas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for matching labels/values\n",
    "import numpy as np\n",
    "print(atlas_labels, np.unique(yeoatlas.get_fdata(), return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiLabelsMasker, MultiNiftiLabelsMasker\n",
    "\n",
    "lm = NiftiLabelsMasker(labels_img = yeoatlas, mask_img= bin_mni_mask, labels = atlas_labels,resampling_target = 'data', standardize = 'zscore_sample', verbose=0)\n",
    "lm.fit(mni_resampled[1])\n",
    "lm.generate_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "atlas = datasets.fetch_atlas_msdl()\n",
    "# Loading atlas image stored in 'maps'\n",
    "atlas_filename = atlas[\"maps\"]\n",
    "# Loading atlas data stored in 'labels'\n",
    "\n",
    "from nilearn.maskers import NiftiMapsMasker, MultiNiftiMapsMasker  \n",
    "\n",
    "masker = NiftiMapsMasker(\n",
    "            maps_img=atlas_filename,\n",
    "            standardize=\"zscore_sample\",\n",
    "            verbose=5,\n",
    "            resampling_target=\"data\",\n",
    "        )\n",
    "masker.fit(resampled[0])\n",
    "\n",
    "time_series = masker.transform(resampled[0], confounds=data.confounds_pre_hyp[0])\n",
    "#plot_roi(\n",
    "    #masker.mask_img_,bg_img = mean_img(atlas), title=\"Maps mask from multi-masker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.generate_report(displayed_maps=[2, 6, 7,])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> MapsMasker with mask from MultiMasker ('epi' strategy)\n",
    "--> not aligned with atlas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiMapsMasker, MultiNiftiMapsMasker  \n",
    "\n",
    "masker = MultiNiftiMapsMasker(\n",
    "            maps_img=atlas,\n",
    "            t_r=3,\n",
    "            smoothing_fwhm=6,\n",
    "            standardize=\"zscore_sample\",\n",
    "            verbose=5,\n",
    "            resampling_target=\"data\",\n",
    "        )\n",
    "masker.fit(resampled)\n",
    "results['pre_series'] = [masker.transform(ts, confounds = cf) for ts, cf in zip(resampled, data.confounds_pre_hyp)]\n",
    "inv = [masker.inverse_transform(ts) for ts in results['pre_series']]\n",
    "plot_roi(\n",
    "    masker.mask_img_,bg_img = mean_img(atlas), title=\"Maps mask from multi-masker\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiMapsMasker, MultiNiftiMapsMasker  \n",
    "\n",
    "masker = MultiNiftiMapsMasker(\n",
    "            maps_img=atlas,\n",
    "            t_r=3,\n",
    "            smoothing_fwhm=6,\n",
    "            standardize=\"zscore_sample\",\n",
    "            verbose=5,\n",
    "            resampling_target=\"data\",\n",
    "        )\n",
    "masker.fit(mni_resampled)\n",
    "results['pre_series'] = [masker.transform(ts, confounds = cf) for ts, cf in zip(mni_resampled, data.confounds_pre_hyp)]\n",
    "inv = [masker.inverse_transform(ts) for ts in results['pre_series']]\n",
    "plot_roi(\n",
    "    masker.mask_img_,bg_img = mean_img(atlas), title=\"Maps mask from multi-masker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['pre_series'][0].shape\n",
    "inv[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nilearn.maskers import MultiNiftiMapsMasker   \n",
    "\n",
    "multi_mapsmasker = MultiNiftiMapsMasker(\n",
    "            maps_img=atlas,\n",
    "            mask_img=voxel_masker.mask_img_,\n",
    "            t_r=3,\n",
    "            smoothing_fwhm=6,\n",
    "            standardize=\"zscore_sample\",\n",
    "            verbose=5,\n",
    "            resampling_target=\"data\",\n",
    "        )\n",
    "multi_mapsmasker.fit(resampled_series)\n",
    "print(multi_mapsmasker.mask_img_.shape, multi_mapsmasker.transform(resampled_series[0]).shape)\n",
    "samp_multimaps0 = multi_mapsmasker.transform(resampled_series[0])\n",
    "plot_roi(\n",
    "    masker.mask_img_,bg_img = m_im, title=\"Maps mask from multi-masker\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_mapsmasker.generate_report()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing single img transform from MultiMaps vs maps : gives same output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(samp_maps0.shape, samp_multimaps0.shape)\n",
    "(samp_maps0 == samp_multimaps0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_prob_atlas\n",
    "\n",
    "plot_prob_atlas(atlas, bg_img = voxel_masker.mask_img_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sphere-ROI correlation to plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(results[\"pre_series\"][0].shape, results[\"seed_pre_series\"][0].shape)\n",
    "[seed_masker.transform(ts) for ts in resampled_series]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"voxel_pre_series\"] = [mnm.transform(ts) for ts in resampled_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from nilearn.maskers import NiftiSpheresMasker\n",
    "\n",
    "sphere_coord = [(54, -28, 26)]\n",
    "seed_masker = NiftiSpheresMasker(\n",
    "    sphere_coord, radius=8, standardize=\"zscore_sample\"\n",
    ")\n",
    "\n",
    "seed_masker.fit(resampled_series)\n",
    "\n",
    "results[\"seed_pre_series\"] = [seed_masker.transform(ts) for ts in resampled_series]\n",
    "results[\"seed_to_pre_correlations\"] = [\n",
    "        (np.dot(brain_time_series.T, seed_time_series) / seed_time_series.shape[0])\n",
    "        for brain_time_series, seed_time_series in zip(\n",
    "            results[\"voxel_pre_series\"], results[\"seed_pre_series\"]\n",
    "        )\n",
    "    ]    \n",
    "\n",
    "results[\"mean_seed_pre_connectome\"] = np.mean(\n",
    "        results[\"seed_to_pre_correlations\"], axis=0\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"mean_seed_pre_connectome\"].T.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.datasets import fetch_atlas_yeo_2011\n",
    "\n",
    "# Fetch the Yeo-17 atlas\n",
    "atlas = fetch_atlas_yeo_2011()\n",
    "\n",
    "# Access the region labels\n",
    "region_labels = atlas['labels']\n",
    "\n",
    "# Print the region labels\n",
    "for label in region_labels:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed_to_voxel_correlations_img = mnm.inverse_transform(\n",
    "    results[\"mean_seed_pre_connectome\"].T\n",
    ")\n",
    "\n",
    "display = plotting.plot_stat_map(\n",
    "    seed_to_voxel_correlations_img,\n",
    "    threshold=0.5,\n",
    "    vmax=1,\n",
    "    cut_coords=sphere_coord[0],\n",
    "    title=\"Seed-to-voxel correlation (OP seed)\",\n",
    ")\n",
    "display.add_markers(\n",
    "    marker_coords=sphere_coord[0], marker_color=\"g\", marker_size=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.datasets import fetch_miyawaki2008\n",
    "\n",
    "dataset = fetch_miyawaki2008()\n",
    "\n",
    "# training data starts after the first 12 files\n",
    "fmri_random_runs_filenames = dataset.func[12:]\n",
    "stimuli_random_runs_filenames = dataset.label[12:]\n",
    "\n",
    "# training data starts after the first 12 files\n",
    "fmri_random_runs_filenames = dataset.func[12:]\n",
    "stimuli_random_runs_filenames = dataset.label[12:]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nilearn.maskers import MultiNiftiMasker\n",
    "\n",
    "masker = MultiNiftiMasker(\n",
    "    mask_img=dataset.mask, detrend=True, standardize=\"zscore_sample\"\n",
    ")\n",
    "masker.fit()\n",
    "fmri_data = masker.transform(fmri_random_runs_filenames)\n",
    "\n",
    "# shape of the binary (i.e. black and wihte values) image in pixels\n",
    "stimulus_shape = (10, 10)\n",
    "\n",
    "# We load the visual stimuli from csv files\n",
    "stimuli = []\n",
    "for stimulus_run in stimuli_random_runs_filenames:\n",
    "    stimuli.append(\n",
    "        np.reshape(\n",
    "            np.loadtxt(stimulus_run, dtype=int, delimiter=\",\"),\n",
    "            (-1,) + stimulus_shape,\n",
    "            order=\"F\",\n",
    "        )\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
