{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60cc354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from nilearn import datasets\n",
    "dataset = datasets.fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm')\n",
    "atlas_filename = dataset.maps\n",
    "labels = dataset.labels\n",
    "plotting.plot_roi(atlas_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd81b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiLabelsMasker\n",
    "masker = NiftiLabelsMasker(labels_img=atlas_filename, standardize=True)\n",
    "time_series = masker.fit_transform(frmi_files,\n",
    "                                   confounds=confounds_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4778284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#atlas = datasets.fetch_atlas_basc_multiscale_2015(version=\"sym\", resolution=64)\n",
    "#atlas_filename = datasets.fetch_atlas_yeo_2011()['thick_17']\n",
    "labels_cortical  = ['Visual', 'Somatosensory', 'Dorsal Attention', 'Ventral Attention', 'Limbic', 'Frontoparietal', 'Default']\n",
    "from nilearn import plotting\n",
    "#plotting.plot_roi(atlas_filename)\n",
    "difumo_names = pd.read_csv(r\"C:\\Users\\Dylan\\Desktop\\UM_Bsc_neurocog\\E22\\Projet_Ivado_rainvillelab\\connectivity_project\\resting_state_hypnosis\\atlases\\atlas_difumo64\\labels_64_dictionary.csv\")[\"Difumo_names\"]\n",
    "print(difumo_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf9644f4",
   "metadata": {},
   "source": [
    ">## Load data and get timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa0f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.maskers import NiftiMapsMasker, NiftiLabelsMasker, MultiNiftiLabelsMasker, MultiNiftiMapsMasker\n",
    "import func\n",
    "import main_con \n",
    "import importlib\n",
    "importlib.reload(main_con)\n",
    "\n",
    "p = r'E:\\Users\\Dylan\\Desktop\\UdeM_H22\\E_PSY3008\\data_desmartaux\\HYPNOSIS_ASL_DATA'\n",
    "data = func.load_data(p)\n",
    "#idcs = [i + 1 for i in range(0,len(data.subjects))]\n",
    "conditions = ['pre_hyp', 'post_hyp', 'diff']\n",
    "pre_data = data.pre_hyp\n",
    "post_data = data.post_hyp\n",
    "results = main_con.con_matrix(p, atlas_name='difumo64', atlas_type='maps', connectivity_measure='precision', verbose=False)\n",
    "\n",
    "results.keys()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a98c141",
   "metadata": {},
   "source": [
    "># Stats model on connectomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0390581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob as glob\n",
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import func\n",
    "from nilearn.maskers import NiftiMapsMasker, NiftiLabelsMasker, NiftiMasker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1348c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(res_path, folder):\n",
    "    path = glob.glob(os.path.join(res_path, folder, 'features*'))\n",
    "    features = dict()\n",
    "    keys = ['pre', 'post', 'contrast']\n",
    "    for p, key in zip(path,keys):\n",
    "        features[key] = np.load(p, allow_pickle=True)\n",
    "    return features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ec7fbd8",
   "metadata": {},
   "source": [
    "# Difumo with precision estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to = r'C:\\Users\\Dylan\\Desktop\\UM_Bsc_neurocog\\E22\\Projet_Ivado_rainvillelab\\results\\test_connec' \n",
    "f = r'Hypnosis_variables_20190114_pr_jc.xlsx'\n",
    "res_path = r'C:\\Users\\Dylan\\Desktop\\UM_Bsc_neurocog\\E22\\Projet_Ivado_rainvillelab\\results\\results_con'\n",
    "xlsx_path = r'C:\\Users\\Dylan\\Desktop\\UM_Bsc_neurocog\\E22\\Projet_Ivado_rainvillelab\\results\\Hypnosis_variables_20190114_pr_jc.xlsx'\n",
    "folder = 'difumo64_precision'\n",
    "\n",
    "results = dict(pre_series = list(), post_series =  list())\n",
    "rawY = pd.read_excel(xlsx_path, sheet_name=0, index_col=1, header=2).iloc[2:, [19, 39, 48, 67]]\n",
    "rawY.columns= [\"Abs_chge_pain_hypAna\", \"Chge_hypnotic_depth\", \"Mental_relax_absChange\", \"Abs_diff_automaticity\"]\n",
    "cutY = rawY.drop(['APM04*']).iloc[:-6,:] # remove sub04 and last 6 rows\n",
    "Y = cutY.fillna(cutY.astype(float).mean()).astype(float)\n",
    "\n",
    "# X features\n",
    "dict_features = get_features(res_path,folder)\n",
    "print('Loaded Pre/post/contrast feature matrices of shape (N, (64*64-64)/2) :\\n', [dict_features[key].shape for key in dict_features])\n",
    "# rename sub\n",
    "#rename_sub = [f'APM{num}' for num in [sub[4:6] for sub in data.subjects]] # Will rename 'APM_01_H1' with 'APM01'\n",
    "#idcs = [idcs for idcs, index in enumerate(full_y.index) if index in rename_sub]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db07fd5f",
   "metadata": {},
   "source": [
    ">## Classification of pre / post / contrast conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535b00cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import PredictionErrorDisplay\n",
    "def plot_pred(y,y_pred):\n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "    PredictionErrorDisplay.from_predictions(\n",
    "        y,\n",
    "        y_pred=y_pred,\n",
    "        kind=\"actual_vs_predicted\",\n",
    "        subsample=100,\n",
    "        ax=axs[0],\n",
    "        random_state=0,\n",
    "    )\n",
    "    axs[0].set_title(\"Actual vs. Predicted values\")\n",
    "    PredictionErrorDisplay.from_predictions(\n",
    "        y,\n",
    "        y_pred=y_pred,\n",
    "        kind=\"residual_vs_predicted\",\n",
    "        subsample=100,\n",
    "        ax=axs[1],\n",
    "        random_state=0,\n",
    "    )\n",
    "    axs[1].set_title(\"Residuals vs. Predicted Values\")\n",
    "    fig.suptitle(\"Plotting cross-validated predictions\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5729dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification of pre/post\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import  ShuffleSplit, train_test_split,cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x1 = dict_features['post']\n",
    "x2 = dict_features['pre']\n",
    "x3 = dict_features['contrast']\n",
    "binary = False\n",
    "if binary:\n",
    "        y_cond = np.concatenate((np.zeros(x1.shape[0]), np.ones(x2.shape[0])),axis=0)\n",
    "        X = np.concatenate((x1, x2), axis=0)\n",
    "else:\n",
    "        y_cond = np.concatenate((np.zeros(x1.shape[0]), np.ones(x2.shape[0]), np.full(x3.shape[0], 2)),axis=0)\n",
    "        X = np.concatenate((x1, x2, x3), axis=0)\n",
    "print('X.shape :', X.shape, 'y.shape :', y_cond.shape)\n",
    "pca = True\n",
    "if pca:\n",
    "        clf1 = make_pipeline(StandardScaler(),PCA(n_components=0.80), LogisticRegression(max_iter = 100))\n",
    "        clf2 = make_pipeline(StandardScaler(),PCA(n_components=0.80), KNeighborsClassifier()) #RandomForestClassifier(n_estimators=50))\n",
    "        clf3 = make_pipeline(StandardScaler(),PCA(n_components=0.80), SVC(kernel = 'linear',gamma='auto', probability=True))\n",
    "        \n",
    "else:\n",
    "        # Without PCA\n",
    "        clf1 = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "        clf2 = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100))\n",
    "        clf3 = make_pipeline(StandardScaler(), SVC(kernel = 'linear',gamma='auto', probability=True))\n",
    "\n",
    "eclf = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('rf', clf2), ('svc', clf3)],\n",
    "        voting='hard')\n",
    "\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.25)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print('Ensemble clf cross val. scores :', cross_val_score(eclf, X, y_cond, cv=ss))\n",
    "\n",
    "# Logistic regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_cond, test_size=0.3, random_state=3)\n",
    "clf1.fit(X_train, y_train)\n",
    "print('LogisticRegression cross val. scores :', cross_val_score(clf1, X, y_cond, cv=ss))\n",
    "\n",
    "#SVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_cond, test_size=0.3, random_state=3)\n",
    "clf3.fit(X_train, y_train)     \n",
    "#print(clf3.score(X_test, y_test))\n",
    "print('SVC cross val scores :', cross_val_score(clf3, X, y_cond, cv=ss))\n",
    "\n",
    "# Confusion matrix with SVC\n",
    "model = clf3\n",
    "conf_matrix_list = []\n",
    "acc = []\n",
    "for train_index, test_index in ss.split(X, y_cond):\n",
    "\n",
    "   X_train, X_test = X[train_index], X[test_index]\n",
    "   y_train, y_test = y_cond[train_index], y_cond[test_index]\n",
    "\n",
    "   model.fit(X_train, y_train)\n",
    "   acc.append(accuracy_score(y_test, model.predict(X_test)))\n",
    "   conf_matrix = confusion_matrix(y_test, model.predict(X_test))\n",
    "   conf_matrix_list.append(conf_matrix)\n",
    "print([\"{:.2f}%\".format(acc[i]) for i in range (len(acc))])\n",
    "print('Mean SVC confusion matrix :\\n', np.mean(conf_matrix_list, axis=0))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=np.mean(conf_matrix_list, axis=0),display_labels=['post', 'pre', 'contrast'])\n",
    "#disp.set_title('Mean SVC shufflesplit(5 iter)')\n",
    "\n",
    "disp.plot( cmap=plt.cm.Blues)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91a9d1b7",
   "metadata": {},
   "source": [
    ">### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe8bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = dict_features['contrast']\n",
    "X = \n",
    "print(X.shape)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.80)\n",
    "pca.fit(X)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "#print(pca.singular_values_) \n",
    "x_pca = pca.transform(X)\n",
    "print(X.shape, x_pca.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0d8f38b",
   "metadata": {},
   "source": [
    "## Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4712ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glm_func\n",
    "from statsmodels.stats.multitest import fdrcorrection   \n",
    "\n",
    "y_col = [\"Abs_chge_pain_hypAna\", \"Chge_hypnotic_depth\", \"Mental_relax_absChange\", \"Abs_diff_automaticity\"]\n",
    "x = x_pca\n",
    "\n",
    "for col in y_col:\n",
    "    \n",
    "    y = np.array(Y[[col]]).reshape(-1)\n",
    "    y = preprocessing.normalize(y.reshape(-1, 1),axis=0).reshape(-1)\n",
    "    print(y.shape)\n",
    "    #y_log = np.log(y)\n",
    "\n",
    "    # Models\n",
    "    lin_reg = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "    #lin_reg_log = sm.OLS(y_log, x_constant).fit()\n",
    "    lin_reg_wls = sm.WLS(y, sm.add_constant(x)).fit()\n",
    "    #lin_reg_wls_log = sm.WLS(y_log, x_constant).fit()\n",
    "\n",
    "    from scipy.stats.mstats import winsorize\n",
    "    #win_data = winsorize(np.array(data), limits=[0.05, 0.05])\n",
    "    #win_reg_lin = sm.OLS(y_norm, win_data).fit() \n",
    "\n",
    "    ols_res = lin_reg.summary()\n",
    "    print(col, '\\n-----------',ols_res)\n",
    "    corr_ps = fdrcorrection(lin_reg.pvalues)[0]\n",
    "    for i in range(len(corr_ps)):\n",
    "        if corr_ps[i] == True:\n",
    "            print('Feature', i, 'is significant with FDR correction')\n",
    "     \n",
    "    import func\n",
    "    # (Ŷi,Yi) plot [0] and (Ŷi , error estimate Ê ) plot at [1]\n",
    "    glm_func.linearity_test(lin_reg, y)\n",
    "    \n",
    "    # resid/Vis. for each feature\n",
    "    #for i in range(sm.add_constant(x).shape[1]):\n",
    "        #x_constant = pd.DataFrame(sm.add_constant(x))\n",
    "        #glm_func.resid_vi(x_constant.iloc[:,i],resids, x_constant.columns[i])   \n",
    "\n",
    "    #plt.hist(resids)\n",
    "    #plt.show()\n",
    "    #func.linearity_test(lin_reg_log, data[yname])\n",
    "    #func.linearity_test(win_reg_lin, data[yname])\n",
    "# Stat. test\n",
    "    model = SVR()\n",
    "    ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "    print(cross_val_score(model, x, y, cv=ss))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e69962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "yname = 'automaticity'\n",
    "cut_y_auto = y_auto['Unnamed: 68'].iloc[2:-6]\n",
    "y_auto.drop([5],inplace=True) # drop sub04\n",
    "\n",
    "y = y_auto.fillna(y_auto.astype(float).mean()).astype(float)\n",
    "# Normalize \n",
    "y_norm = preprocessing.normalize(np.array(y).reshape(-1,1),axis=0)\n",
    "\n",
    "#y_log = np.log(y)\n",
    "\n",
    "x = data_contrast\n",
    "x_constant = sm.add_constant(x)\n",
    "\n",
    "# Models\n",
    "lin_reg = sm.OLS(y_norm, x_constant).fit()\n",
    "#lin_reg_log = sm.OLS(y_log, x_constant).fit()\n",
    "lin_reg_wls = sm.WLS(y, x_constant).fit()\n",
    "#lin_reg_wls_log = sm.WLS(y_log, x_constant).fit()\n",
    "\n",
    "from scipy.stats.mstats import winsorize\n",
    "win_data = winsorize(np.array(data), limits=[0.05, 0.05])\n",
    "#win_reg_lin = sm.OLS(y_norm, win_data).fit() \n",
    "\n",
    "ols_res = lin_reg.summary()\n",
    "print(ols_res)pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ebc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = plotting.find_parcellation_cut_coords(labels_img=atlas_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6711b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_connectome(\n",
    "    mean_correlation_matrix,\n",
    "    coordinates,\n",
    "    edge_threshold=\"10%\",\n",
    "    title=\"yeo (func)\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "802aa776",
   "metadata": {},
   "source": [
    "## *Visualization of Atlases, connectomes and connectivity matrix*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a186000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import func \n",
    "import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn.maskers import NiftiMapsMasker, NiftiLabelsMasker\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "import func\n",
    "from nilearn import datasets, plotting, image\n",
    "from nilearn.regions import connected_label_regions\n",
    "from nilearn.plotting import plot_matrix, find_probabilistic_atlas_cut_coords\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c68ce10f",
   "metadata": {},
   "source": [
    ">## Pre, post, contrast with yeo 14 ROIs bilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d292c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas, labels, _ = func.load_choose_atlas('yeo_7', bilat=True)\n",
    "\n",
    "title = 'Post-pre (Z; 99%; Correlation; yeo7)'\n",
    "#view = plotting.view_connectome(results['zcontrast_mean_connectome'], find_probabilistic_atlas_cut_coords(atlas),edge_threshold=\"99%\", title = title)\n",
    "\n",
    "p = r'C:\\Users\\Dylan\\Desktop\\UM_Bsc_neurocog\\E22\\Projet_Ivado_rainvillelab\\results\\results_con\\yeo7_correlation\\contrast_mean_connectome.npy'\n",
    "view = plotting.view_connectome(np.load(p), find_probabilistic_atlas_cut_coords(atlas),edge_threshold=None, title = title)\n",
    "\n",
    "# In a Jupyter notebook, if ``view`` is the output of a cell, it will\n",
    "# be displayed below the cell\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = r'C:\\Users\\Dylan\\Desktop\\UM_Bsc_neurocog\\E22\\Projet_Ivado_rainvillelab\\results\\results_con\\difumo64_precision\\contrast_mean_connectome.npy'\n",
    "view = plotting.view_connectome(np.load(p), find_probabilistic_atlas_cut_coords(atlas),edge_threshold=\"99%\", title = title)\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2991a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(results['zcontrast_mean_connectome'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aab616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import func \n",
    "import importlib\n",
    "importlib.reload(func) \n",
    "\n",
    "root = r'C:\\Users\\Dylan\\Desktop\\UM_Bsc_neurocog\\E22\\Projet_Ivado_rainvillelab\\results\\results_con'\n",
    "atlas_name = 'Yeo_14_bilateral '\n",
    "atlas, labels, _ = func.load_choose_atlas('yeo_7', bilat=True)\n",
    "func.out(root,'yeo7_precision', list(labels), atlas, atlas_name,conditions = ['Pre-Hyp', 'Post-Hyp', 'Post-pre'], mask_bilat = True, plot_con = True, con_tresh = '90%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ce5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for time_serie, label in zip(time_series.T, labels):\n",
    "    plt.plot(time_serie, label=label)\n",
    "\n",
    "plt.title(\"Default Mode Network Time Series\")\n",
    "plt.xlabel(\"Scan number\")\n",
    "plt.ylabel(\"Normalized signal\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ed08262",
   "metadata": {},
   "source": [
    ">## Comparison of different covariance estimators for yeo 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fc4d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(results['pre_series']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c332e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(func) \n",
    "\n",
    "# Load timeseries\n",
    "\n",
    "print([ts.shape for ts in results[\"pre_series\"]])\n",
    "print([ts.shape for ts in results[\"post_series\"]])\n",
    "\n",
    "func.graphLasso_covariance_estim(results['pre_series'],cond = 'Pre-Hyp', atlas_name = 'yeo_7', tresh='90%')\n",
    "print('-------------------')\n",
    "func.graphLasso_covariance_estim(results['post_series'],cond = 'Post-Hyp', atlas_name = 'yeo_7', tresh='90%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a45c9ac7",
   "metadata": {},
   "source": [
    ">## Pre, post and contrast for DiFuMo 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f038a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.keys())\n",
    "filt_labels = []\n",
    "for row in results['zcontrast_mean_connectome']:\n",
    "    for idx, val in enumerate(row):\n",
    "        if val >2:\n",
    "            filt_labels.append(labels[idx])\n",
    "print(pd.DataFrame(filt_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import func \n",
    "import importlib\n",
    "importlib.reload(func) \n",
    "\n",
    "root = r'C:\\Users\\Dylan\\Desktop\\UM_Bsc_neurocog\\E22\\Projet_Ivado_rainvillelab\\results\\results_con'\n",
    "atlas_name = 'difumo64'\n",
    "atlas, labels,_, confounds = func.load_choose_atlas(atlas_name, bilat=False)\n",
    "func.out(root,'difumo64_correlation', list(labels), atlas,atlas_name, conditions = ['Pre-Hyp', 'Post-Hyp', 'Post-pre'], con_tresh = '98%',mask_bilat = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5c9f0f1",
   "metadata": {},
   "source": [
    "## Precision estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174badfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import func \n",
    "import importlib\n",
    "importlib.reload(func) \n",
    "\n",
    "root = r'C:\\Users\\Dylan\\Desktop\\UM_Bsc_neurocog\\E22\\Projet_Ivado_rainvillelab\\results\\results_con'\n",
    "atlas_name = 'difumo64'\n",
    "atlas, labels,_, confounds = func.load_choose_atlas(atlas_name, bilat=False)\n",
    "func.out(root,'difumo64_precision', list(labels), atlas,atlas_name, conditions = ['Pre-Hyp', 'Post-Hyp', 'Post-pre'],cov_estim = 'precision cov.', con_tresh = '98%',mask_bilat = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d0683b0",
   "metadata": {},
   "source": [
    "\n",
    "### Plot timeseries from ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da09a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "atlas, labels, _ = func.load_choose_atlas('yeo_7', bilat=True)\n",
    "\n",
    "for time_serie, label in zip(np.array(results[\"pre_series\"]).mean(axis=0).T, labels):\n",
    "    plt.plot(time_serie, label=label)\n",
    "\n",
    "    plt.title(\"Default Mode Network Time Series\")\n",
    "    plt.xlabel(\"Scan number\")\n",
    "    plt.ylabel(\"Normalized signal\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d72c83ec",
   "metadata": {},
   "source": [
    "## Scale comparison\n",
    "\n",
    "difumo precision difumo correlation in  // standardize=\"zscore_sample\" //  \"psc\" // "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e47b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path = r'C:\\Users\\Dylan\\Desktop\\UM_Bsc_neurocog\\E22\\Projet_Ivado_rainvillelab\\results\\results_con'\n",
    "\n",
    "folder = 'difumo64_precision'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f6ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connectivity data linear model\n",
    "p1 = r'C:\\Users\\Dylan\\Desktop\\UM_Bsc_neurocog\\E22\\Projet_Ivado_rainvillelab\\results\\partial_connect_hyp_yeo17thick'\n",
    "data_pre = np.load(os.path.join(p1, 'features_pre.npy'))\n",
    "data_post = np.load(os.path.join(p1, 'features_post.npy'))\n",
    "data_contrast = np.load(os.path.join(p1, 'features_contrast.npy'))\n",
    "#fully_auto = pd.read_csv(os.path.join(p1, 'Y.csv'))\n",
    "\n",
    "pre_mean17 = np.load(os.path.join(p1, 'pre_hyp_mean_connectome.npy'))\n",
    "post_mean17 = np.load(os.path.join(p1, 'post_hyp_mean_connectome.npy'))\n",
    "contrast_mean17 = np.load(os.path.join(p1, 'contrast_mean_connectome.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81db60a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = r'C:\\Users\\Dylan\\Desktop\\UM_Bsc_neurocog\\E22\\Projet_Ivado_rainvillelab\\results\\results_con\\yeo7_correlation'\n",
    "data_pre = np.load(os.path.join(p, 'features_pre.npy'))\n",
    "data_post = np.load(os.path.join(p, 'features_post.npy'))\n",
    "data_contrast = np.load(os.path.join(p, 'features_contrast.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a3ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_mean = np.load(os.path.join(p, 'pre_hyp_mean_connectome.npy'))\n",
    "post_mean = np.load(os.path.join(p, 'post_hyp_mean_connectome.npy'))\n",
    "contrast_mean = np.load(os.path.join(p, 'contrast_mean_connectome.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d292ffd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = ['Visual', 'Somatosensory', 'Dorsal Attention', 'Ventral Attention', 'Limbic', 'Frontoparietal', 'Default']\n",
    "names = ['pre', 'post', 'contrast']\n",
    "for i, correlation_matrix in enumerate([pre_mean, post_mean, contrast_mean]):#[results['pre_mean_connetomes'], results['post_mean_connetomes']]:\n",
    "            np.fill_diagonal(correlation_matrix, 0)\n",
    "            plotting.plot_matrix(correlation_matrix, labels=labels, colorbar=True, vmax=0.8, vmin=-0.8)\n",
    "            plot_connectome(correlation_matrix, atlas_filename, names[i])\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05b8f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "yname = 'automaticity'\n",
    "\n",
    "x = data_contrast\n",
    "x_constant = sm.add_constant(x)\n",
    "# Models\n",
    "lin_reg = sm.OLS(y, x_constant).fit()\n",
    "lin_reg_wls = sm.WLS(y, x_constant).fit()\n",
    "\n",
    "from scipy.stats.mstats import winsorize\n",
    "win_data = winsorize(np.array(data), limits=[0.05, 0.05])\n",
    "#win_reg_lin = sm.OLS(y_norm, win_data).fit() \n",
    "\n",
    "ols_res = lin_reg.summary()\n",
    "print(ols_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e7ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_pre\n",
    "x_constant = sm.add_constant(x)\n",
    "# Models\n",
    "lin_reg = sm.OLS(y, x_constant).fit()\n",
    "lin_reg_wls = sm.WLS(y, x_constant).fit()\n",
    "\n",
    "from scipy.stats.mstats import winsorize\n",
    "win_data = winsorize(np.array(data), limits=[0.05, 0.05])\n",
    "#win_reg_lin = sm.OLS(y_norm, win_data).fit() \n",
    "\n",
    "ols_res = lin_reg.summary()\n",
    "print(ols_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb95b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478941d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = data_post\n",
    "x_constant = sm.add_constant(x)\n",
    "# Models\n",
    "lin_reg = sm.OLS(y, x_constant).fit()\n",
    "lin_reg_wls = sm.WLS(y, x_constant).fit()\n",
    "\n",
    "from scipy.stats.mstats import winsorize\n",
    "win_data = winsorize(np.array(data), limits=[0.05, 0.05])\n",
    "#win_reg_lin = sm.OLS(y_norm, win_data).fit() \n",
    "\n",
    "ols_res = lin_reg.summary()\n",
    "print(ols_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70d77f16",
   "metadata": {},
   "source": [
    "## ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d3954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "X = data_post \n",
    "\n",
    "clf = Ridge(alpha=1.0)\n",
    "clf.fit(X, y)\n",
    "coefs = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pwd, '\\n', atlas_path)\n",
    "print(os.path.join(pwd, atlas_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e003d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "atlas_path = r'C:\\Users\\Dylan\\Desktop\\UM_Bsc_neurocog\\E22\\Projet_Ivado_rainvillelab\\connectivity_project\\resting_state_hypnosis\\atlases\\atlas_difumo64\\64difumo2mm_maps.nii.gz'\n",
    "atlas = nib.load(atlas_path)\n",
    "\n",
    "atlas_labels = pd.read_csv(r'C:\\Users\\Dylan\\Desktop\\UM_Bsc_neurocog\\E22\\Projet_Ivado_rainvillelab\\connectivity_project\\resting_state_hypnosis\\atlases\\atlas_difumo64\\labels_64_dictionary.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
